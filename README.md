# Mini-Infer

ä¸€ä¸ªè½»é‡çº§çš„æ·±åº¦å­¦ä¹ æ¨ç†æ¡†æ¶ï¼Œç±»ä¼¼äº TensorRTï¼Œæ”¯æŒé«˜æ€§èƒ½æ¨¡å‹æ¨ç†ã€‚

## é¡¹ç›®ç‰¹æ€§

- ğŸš€ **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„æ¨¡å—åˆ’åˆ†ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
- ğŸ”§ **å¯æ‰©å±•åç«¯**: æŠ½è±¡çš„åç«¯æ¥å£ï¼Œæ”¯æŒ CPU å’Œæœªæ¥çš„ GPUï¼ˆCUDAï¼‰åç«¯
- ğŸ“Š **è®¡ç®—å›¾**: å®Œæ•´çš„è®¡ç®—å›¾è¡¨ç¤ºå’Œä¼˜åŒ–
- âš¡ **é«˜æ€§èƒ½**: é¢å‘æ€§èƒ½ä¼˜åŒ–çš„è®¾è®¡
- ğŸ§ª **æ˜“äºæµ‹è¯•**: å®Œå–„çš„æµ‹è¯•æ¡†æ¶

## é¡¹ç›®ç»“æ„

```
Mini-Infer/
â”œâ”€â”€ include/                # å…¬å…±å¤´æ–‡ä»¶
â”‚   â””â”€â”€ mini_infer/
â”‚       â”œâ”€â”€ core/          # æ ¸å¿ƒæ•°æ®ç»“æ„ï¼ˆTensor, Allocatorç­‰ï¼‰
â”‚       â”œâ”€â”€ backends/      # åç«¯æŠ½è±¡å±‚ï¼ˆCPU, CUDAï¼‰
â”‚       â”œâ”€â”€ operators/     # ç®—å­å®ç°
â”‚       â”œâ”€â”€ graph/         # è®¡ç®—å›¾
â”‚       â”œâ”€â”€ runtime/       # è¿è¡Œæ—¶å¼•æ“
â”‚       â””â”€â”€ utils/         # å·¥å…·ç±»
â”œâ”€â”€ src/                   # æºæ–‡ä»¶å®ç°
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ backends/
â”‚   â”œâ”€â”€ operators/
â”‚   â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ runtime/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ tests/                 # æµ‹è¯•
â”œâ”€â”€ examples/              # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â””â”€â”€ CMakeLists.txt         # CMake é…ç½®æ–‡ä»¶
```

## æ„å»ºè¦æ±‚

### åŸºç¡€ä¾èµ–

- CMake 3.18+
- C++17 ç¼–è¯‘å™¨
  - MSVC 2017+ (Windows)
  - GCC 7+ (Linux)
  - Clang 5+ (macOS)

### æ¨èï¼šä½¿ç”¨ Conan åŒ…ç®¡ç†å™¨ï¼ˆè·¨å¹³å°ï¼‰

**å¼ºçƒˆæ¨èä½¿ç”¨ Conan è¿›è¡Œä¾èµ–ç®¡ç†**ï¼Œå®ƒæä¾›çœŸæ­£çš„è·¨å¹³å°ä¸€é”®å¼æ„å»ºä½“éªŒï¼š

```bash
# å®‰è£… Conan (æ‰€æœ‰å¹³å°)
pip install conan

# åˆå§‹åŒ– Conan profile
conan profile detect --force
```

ä½¿ç”¨ Conan åï¼Œæ‰€æœ‰ä¾èµ–ï¼ˆåŒ…æ‹¬ Protobufï¼‰éƒ½ä¼šè‡ªåŠ¨ä¸‹è½½å’Œé…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨å®‰è£…ï¼

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒï¼š[Conan æ„å»ºæŒ‡å—](docs/CONAN_BUILD_GUIDE.md)

## å¿«é€Ÿå¼€å§‹

### æ„å»ºé¡¹ç›®

#### ğŸš€ æ–¹å¼ 1: ä½¿ç”¨ Conanï¼ˆæ¨èï¼Œè·¨å¹³å°ä¸€é”®å¼ï¼‰

**Windows:**
```powershell
# ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ¨èï¼Œä¸€é”®å®Œæˆæ‰€æœ‰æ­¥éª¤ï¼‰
.\build.ps1

# æˆ–æ‰‹åŠ¨æ‰§è¡Œï¼ˆDebug æ„å»º + ONNX æ”¯æŒï¼‰
# æ­¥éª¤ 1: å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•ï¼‰
conan install . -s build_type=Debug -o enable_onnx=True --build=missing

# æ­¥éª¤ 2: é…ç½® CMakeï¼ˆè‡ªåŠ¨ä½¿ç”¨ Conan ç”Ÿæˆçš„é¢„è®¾ï¼‰
cmake --preset conan-debug

# æ­¥éª¤ 3: ç¼–è¯‘
cmake --build build/Debug

# æ­¥éª¤ 4: è¿è¡Œç¤ºä¾‹
.\build\Debug\bin\onnx_parser_example.exe .\models\python\lenet5\models\lenet5.onnx

# Release æ„å»º
conan install . -s build_type=Release -o enable_onnx=True --build=missing
cmake --preset conan-release
cmake --build build/Release
```

**Linux/macOS:**
```bash
# ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ¨èï¼Œä¸€é”®å®Œæˆæ‰€æœ‰æ­¥éª¤ï¼‰
chmod +x build.sh
./build.sh

# æˆ–æ‰‹åŠ¨æ‰§è¡Œï¼ˆDebug æ„å»º + ONNX æ”¯æŒï¼‰
# æ­¥éª¤ 1: å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•ï¼‰
conan install . -s build_type=Debug -o enable_onnx=True --build=missing

# æ­¥éª¤ 2: é…ç½® CMakeï¼ˆè‡ªåŠ¨ä½¿ç”¨ Conan ç”Ÿæˆçš„é¢„è®¾ï¼‰
cmake --preset conan-debug

# æ­¥éª¤ 3: ç¼–è¯‘
cmake --build build/Debug

# æ­¥éª¤ 4: è¿è¡Œç¤ºä¾‹
./build/Debug/bin/onnx_parser_example ./models/python/lenet5/models/lenet5.onnx

# Release æ„å»º
conan install . -s build_type=Release -o enable_onnx=True --build=missing
cmake --preset conan-release
cmake --build build/Release
```

**ğŸ‰ Conan ä¼˜åŠ¿:**
- âœ… **çœŸæ­£çš„è·¨å¹³å°**: Windows/Linux/macOS å®Œå…¨ç›¸åŒçš„å‘½ä»¤
- âœ… **è‡ªåŠ¨ä¾èµ–ç®¡ç†**: è‡ªåŠ¨ä¸‹è½½å’Œé…ç½® Protobufã€Abseil ç­‰æ‰€æœ‰ä¾èµ–
- âœ… **è‡ªåŠ¨ ONNX é…ç½®**: è‡ªåŠ¨ä¸‹è½½ proto æ–‡ä»¶ã€ç”Ÿæˆ C++ ä»£ç 
- âœ… **é€‰é¡¹è‡ªåŠ¨ä¼ é€’**: `-o enable_onnx=True` è‡ªåŠ¨è½¬æ¢ä¸º `MINI_INFER_ENABLE_ONNX=ON`
- âœ… **é›¶æ‰‹åŠ¨é…ç½®**: ä¸€æ¡å‘½ä»¤æå®šæ‰€æœ‰äº‹æƒ…
- âœ… **å¯é‡ç°æ„å»º**: é”å®šä¾èµ–ç‰ˆæœ¬ï¼Œç¡®ä¿ä¸€è‡´æ€§

**âš¡ è‡ªåŠ¨åŒ–è„šæœ¬ç‰¹æ€§:**

- âœ… **æ™ºèƒ½ Ninja æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹å¹¶å»ºè®®å®‰è£… Ninja ç”Ÿæˆå™¨ï¼ˆæå‡ 50%+ ç¼–è¯‘é€Ÿåº¦ï¼‰
- âœ… **è‡ªåŠ¨ä¾èµ–ç®¡ç†**: ä¸€é”®å®‰è£…æ‰€æœ‰ä¾èµ–
- âœ… **çµæ´»é…ç½®**: æ”¯æŒæ‰€æœ‰ Conan é€‰é¡¹

**å‚æ•°è¯´æ˜:**
- **Windows**: `.\build.ps1 [-BuildType Debug|Release] [-Clean] [-Test] [-Install]`
- **Linux/macOS**: `./build.sh [-d|-r] [-c] [-t] [-i] [--no-onnx] [--enable-cuda]`

ç¤ºä¾‹ï¼š
```powershell
# Windows: Release æ„å»º + è¿è¡Œæµ‹è¯•
.\build.ps1 -BuildType Release -Test

# Linux: Release æ„å»º + æ¸…ç† + å®‰è£…
./build.sh -r -c -i
```

è¯¦è§ï¼š[å¿«é€Ÿå¼€å§‹æŒ‡å—](QUICK_START.md) | [Conan æ„å»ºæŒ‡å—](docs/CONAN_BUILD_GUIDE.md)

#### æ–¹å¼ 2: ä¼ ç»Ÿæ„å»ºï¼ˆåŸºç¡€åŠŸèƒ½ï¼Œä¸å« ONNXï¼‰

**Windows:**
```powershell
mkdir build && cd build
cmake .. -DMINI_INFER_ENABLE_ONNX=OFF
cmake --build . --config Release
```

**Linux/macOS:**
```bash
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release -DMINI_INFER_ENABLE_ONNX=OFF ..
make -j$(nproc)
```

### CMake é¢„è®¾

Conan ä¼šè‡ªåŠ¨ç”Ÿæˆ CMake é¢„è®¾ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ï¼š

#### å¯ç”¨é¢„è®¾ï¼ˆç”± Conan è‡ªåŠ¨ç”Ÿæˆï¼‰

- `conan-debug` - Debug æ„å»º
- `conan-release` - Release æ„å»º

#### ä½¿ç”¨æµç¨‹

```bash
# 1. Conan å®‰è£…ä¾èµ–ï¼ˆè‡ªåŠ¨ç”Ÿæˆé¢„è®¾ï¼‰
conan install . -s build_type=Debug -o enable_onnx=True --build=missing

# 2. ä½¿ç”¨ç”Ÿæˆçš„é¢„è®¾é…ç½® CMake
cmake --preset conan-debug

# 3. æ„å»ºé¡¹ç›®
cmake --build build/Debug

# 4. è¿è¡Œæµ‹è¯•
ctest --preset conan-debug
```

**è¯´æ˜ï¼š**
- Conan ä¼šæ ¹æ® `build_type` è‡ªåŠ¨ç”Ÿæˆå¯¹åº”çš„é¢„è®¾
- é¢„è®¾åŒ…å«äº†æ‰€æœ‰ä¾èµ–è·¯å¾„ã€ç¼–è¯‘é€‰é¡¹å’Œå·¥å…·é“¾é…ç½®
- `-o enable_onnx=True` ç­‰é€‰é¡¹ä¼šè‡ªåŠ¨ä¼ é€’åˆ° CMake

### è¿è¡Œæµ‹è¯•

```bash
# ä½¿ç”¨ Conan ç”Ÿæˆçš„é¢„è®¾è¿è¡Œæµ‹è¯•
ctest --preset conan-debug     # Debug æ„å»º
ctest --preset conan-release   # Release æ„å»º

# æˆ–ä¼ ç»Ÿæ–¹å¼
cd build/Debug
ctest --output-on-failure
```

### è¿è¡Œç¤ºä¾‹

```bash
# Windows
.\bin\Release\simple_inference.exe
.\bin\Release\build_graph.exe

# Linux/macOS
./bin/simple_inference
./bin/build_graph
```

## ç¼–è¯‘é€‰é¡¹

åœ¨è¿è¡Œ cmake æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹é€‰é¡¹ï¼š

```bash
cmake .. \
  -DMINI_INFER_BUILD_TESTS=ON \        # æ„å»ºæµ‹è¯•ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_BUILD_EXAMPLES=ON \     # æ„å»ºç¤ºä¾‹ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_BUILD_SHARED_LIBS=ON \  # æ„å»ºåŠ¨æ€åº“ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_ENABLE_CUDA=OFF \       # å¯ç”¨ CUDAï¼ˆé»˜è®¤ OFFï¼Œæœªæ¥æ”¯æŒï¼‰
  -DMINI_INFER_ENABLE_ONNX=ON \        # å¯ç”¨ ONNX æ¨¡å‹å¯¼å…¥ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_ENABLE_PROFILING=ON \   # å¯ç”¨æ€§èƒ½åˆ†æï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_ENABLE_LOGGING=ON       # å¯ç”¨æ—¥å¿—ï¼ˆé»˜è®¤ ONï¼‰
```

### ONNX ç›¸å…³é€‰é¡¹

- **`MINI_INFER_ENABLE_ONNX=ON`**: å¯ç”¨ ONNX æ¨¡å‹å¯¼å…¥æ”¯æŒ
  - éœ€è¦å…ˆå®‰è£… Protobuf ä¾èµ–
  - Windows æ¨èä½¿ç”¨ vcpkg å®‰è£…
  - å¦‚æœ Protobuf æœªæ‰¾åˆ°ï¼Œä¼šè‡ªåŠ¨ç¦ç”¨ ONNX æ”¯æŒå¹¶æ˜¾ç¤ºè­¦å‘Š

## ä½¿ç”¨ç¤ºä¾‹

### åˆ›å»ºå¼ é‡

```cpp
#include "mini_infer/core/tensor.h"

using namespace mini_infer;

// åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º [1, 3, 224, 224] çš„å¼ é‡
core::Shape shape({1, 3, 224, 224});
auto tensor = core::Tensor::create(shape, core::DataType::FLOAT32);

// è®¿é—®æ•°æ®
float* data = static_cast<float*>(tensor->data());
```

### æ„å»ºè®¡ç®—å›¾

```cpp
#include "mini_infer/graph/graph.h"

using namespace mini_infer;

// åˆ›å»ºå›¾
auto graph = std::make_shared<graph::Graph>();

// æ·»åŠ èŠ‚ç‚¹
auto input = graph->create_node("input");
auto conv1 = graph->create_node("conv1");
auto output = graph->create_node("output");

// è¿æ¥èŠ‚ç‚¹
graph->connect("input", "conv1");
graph->connect("conv1", "output");

// è®¾ç½®è¾“å…¥è¾“å‡º
graph->set_inputs({"input"});
graph->set_outputs({"output"});
```

### ONNX æ¨¡å‹å¯¼å…¥

```cpp
#include "mini_infer/importers/onnx_parser.h"
#include "mini_infer/runtime/runtime.h"

using namespace mini_infer;

int main() {
    // 1. è§£æ ONNX æ¨¡å‹
    importers::OnnxParser parser;
    parser.set_verbose(true);  // å¯ç”¨è¯¦ç»†æ—¥å¿—
    
    auto graph = parser.parse("model.onnx");
    if (!graph) {
        std::cerr << "Failed to parse ONNX model: " 
                  << parser.get_error() << std::endl;
        return 1;
    }
    
    // 2. åˆ›å»ºè¿è¡Œæ—¶
    runtime::Runtime runtime;
    if (!runtime.load_graph(std::move(graph))) {
        std::cerr << "Failed to load graph" << std::endl;
        return 1;
    }
    
    // 3. å‡†å¤‡è¾“å…¥æ•°æ®
    std::vector<float> input_data(1 * 3 * 224 * 224);
    // ... å¡«å……è¾“å…¥æ•°æ® ...
    
    // 4. æ‰§è¡Œæ¨ç†
    auto outputs = runtime.forward({input_data});
    
    // 5. å¤„ç†è¾“å‡º
    for (const auto& output : outputs) {
        std::cout << "Output size: " << output.size() << std::endl;
    }
    
    return 0;
}
```

**æ³¨æ„**: ONNX åŠŸèƒ½éœ€è¦åœ¨ç¼–è¯‘æ—¶å¯ç”¨ `-DMINI_INFER_ENABLE_ONNX=ON` å¹¶å®‰è£… Protobuf ä¾èµ–ã€‚

### è¿è¡Œæ¨ç†

```cpp
#include "mini_infer/runtime/engine.h"

using namespace mini_infer;

// é…ç½®å¼•æ“
runtime::EngineConfig config;
config.device_type = core::DeviceType::CPU;

// åˆ›å»ºå¼•æ“
runtime::Engine engine(config);

// æ„å»º
engine.build(graph);

// å‡†å¤‡è¾“å…¥
std::unordered_map<std::string, std::shared_ptr<core::Tensor>> inputs;
inputs["input"] = input_tensor;

// æ‰§è¡Œæ¨ç†
std::unordered_map<std::string, std::shared_ptr<core::Tensor>> outputs;
engine.forward(inputs, outputs);
```

## æ¶æ„è®¾è®¡

### ç»„ä»¶æ¶æ„å›¾

```mermaid
graph TB
    %% ç”¨æˆ·å±‚
    User[ç”¨æˆ· User]
    
    %% Runtime å±‚
    Runtime[Runtime è¿è¡Œæ—¶<br/>Engine, EngineConfig]
    
    %% ä¸­é—´å±‚ç»„ä»¶
    Graph[Graph è®¡ç®—å›¾<br/>Node, Graph]
    Backends[Backends åç«¯<br/>Backend, CPUBackend]
    Operators[Operators ç®—å­<br/>Operator, OpFactory]
    
    %% æ ¸å¿ƒå±‚
    Core[Core æ ¸å¿ƒ<br/>Tensor, Shape, DataType, Types, Allocator]
    
    %% å·¥å…·å±‚
    Utils[Utils å·¥å…·<br/>Logger]
    
    %% ä¾èµ–å…³ç³»
    User --> Runtime
    Runtime --> Graph
    Runtime --> Backends
    Runtime --> Operators
    Runtime --> Utils
    
    Graph --> Operators
    Graph --> Core
    
    Operators --> Backends
    Operators --> Core
    
    Backends --> Core
    
    %% æ ·å¼å®šä¹‰
    classDef userStyle fill:#e1f5ff,stroke:#01579b,stroke-width:2px
    classDef runtimeStyle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef componentStyle fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef coreStyle fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    classDef utilStyle fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    
    class User userStyle
    class Runtime runtimeStyle
    class Graph,Backends,Operators componentStyle
    class Core coreStyle
    class Utils utilStyle
```

### æ¨¡å—ä¾èµ–å…³ç³»

```mermaid
graph LR
    Runtime[Runtime<br/>è¿è¡Œæ—¶æ¨¡å—]
    Graph[Graph<br/>å›¾æ¨¡å—]
    Operators[Operators<br/>ç®—å­æ¨¡å—]
    Backends[Backends<br/>åç«¯æ¨¡å—]
    Core[Core<br/>æ ¸å¿ƒæ¨¡å—]
    Utils[Utils<br/>å·¥å…·æ¨¡å—]
    
    Runtime -->|ä¾èµ–| Graph
    Runtime -->|ä¾èµ–| Backends
    Runtime -->|ä¾èµ–| Operators
    Runtime -->|ä¾èµ–| Utils
    
    Graph -->|ä¾èµ–| Operators
    Graph -->|ä¾èµ–| Core
    
    Operators -->|ä¾èµ–| Backends
    Operators -->|ä¾èµ–| Core
    
    Backends -->|ä¾èµ–| Core
    
    style Runtime fill:#ffccbc,stroke:#bf360c
    style Graph fill:#c5cae9,stroke:#283593
    style Operators fill:#b2dfdb,stroke:#004d40
    style Backends fill:#d1c4e9,stroke:#4527a0
    style Core fill:#a5d6a7,stroke:#1b5e20
    style Utils fill:#fff9c4,stroke:#f57f17
```

### æ ¸å¿ƒæ¨¡å—

- **Core**: æä¾›åŸºç¡€æ•°æ®ç»“æ„ï¼ˆTensor, Shape, Allocatorï¼‰
- **Backends**: æŠ½è±¡çš„åç«¯æ¥å£ï¼Œæ”¯æŒä¸åŒç¡¬ä»¶åŠ é€Ÿ
- **Operators**: å„ç§ç®—å­çš„å®ç°ï¼ˆConv2D, Pooling, Activationç­‰ï¼‰
- **Graph**: è®¡ç®—å›¾çš„è¡¨ç¤ºå’Œä¼˜åŒ–
- **Runtime**: æ¨ç†å¼•æ“ï¼Œè´Ÿè´£æ‰§è¡Œè®¡ç®—å›¾
- **Utils**: æ—¥å¿—ã€æ€§èƒ½åˆ†æç­‰å·¥å…·

> ğŸ’¡ **æ›´å¤šæ¶æ„ç»†èŠ‚**: æŸ¥çœ‹ [å®Œæ•´ç»„ä»¶å›¾æ–‡æ¡£](docs/COMPONENT_DIAGRAM.md) äº†è§£è¯¦ç»†çš„ç»„ä»¶äº¤äº’ã€æ•°æ®æµå’Œæ‰©å±•ç‚¹

## å¼€å‘è·¯çº¿

- [x] åŸºç¡€æ¡†æ¶æ­å»º
- [x] CPU åç«¯å®ç°
- [ ] å¸¸ç”¨ç®—å­å®ç°ï¼ˆConv2D, ReLU, MaxPoolç­‰ï¼‰
- [ ] å›¾ä¼˜åŒ–ï¼ˆç®—å­èåˆã€å¸¸é‡æŠ˜å ï¼‰
- [ ] æ¨¡å‹æ ¼å¼æ”¯æŒï¼ˆONNXï¼‰
- [ ] CUDA åç«¯æ”¯æŒ
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆSIMDã€å¤šçº¿ç¨‹ï¼‰
- [ ] FP16 æ”¯æŒ
- [ ] INT8 é‡åŒ–æ”¯æŒ

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

MIT License

## ä½œè€…

James

## è‡´è°¢

æœ¬é¡¹ç›®å— TensorRT å¯å‘ï¼Œæ—¨åœ¨å­¦ä¹ å’Œç†è§£æ¨ç†æ¡†æ¶çš„è®¾è®¡åŸç†ã€‚

