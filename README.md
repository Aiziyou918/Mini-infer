# Mini-Infer

ä¸€ä¸ªè½»é‡çº§çš„æ·±åº¦å­¦ä¹ æ¨ç†æ¡†æ¶ï¼Œç±»ä¼¼äº TensorRTï¼Œæ”¯æŒé«˜æ€§èƒ½æ¨¡å‹æ¨ç†ã€‚

## é¡¹ç›®ç‰¹æ€§

- ğŸš€ **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„æ¨¡å—åˆ’åˆ†ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
- ğŸ”§ **å¯æ‰©å±•åç«¯**: æŠ½è±¡çš„åç«¯æ¥å£ï¼Œæ”¯æŒ CPU å’Œæœªæ¥çš„ GPUï¼ˆCUDAï¼‰åç«¯
- ğŸ“Š **è®¡ç®—å›¾**: å®Œæ•´çš„è®¡ç®—å›¾è¡¨ç¤ºå’Œä¼˜åŒ–
- âš¡ **é«˜æ€§èƒ½**: é¢å‘æ€§èƒ½ä¼˜åŒ–çš„è®¾è®¡
- ğŸ§ª **æ˜“äºæµ‹è¯•**: å®Œå–„çš„æµ‹è¯•æ¡†æ¶

## é¡¹ç›®ç»“æ„

```
Mini-Infer/
â”œâ”€â”€ include/                # å…¬å…±å¤´æ–‡ä»¶
â”‚   â””â”€â”€ mini_infer/
â”‚       â”œâ”€â”€ core/          # æ ¸å¿ƒæ•°æ®ç»“æ„ï¼ˆTensor, Allocatorç­‰ï¼‰
â”‚       â”œâ”€â”€ backends/      # åç«¯æŠ½è±¡å±‚ï¼ˆCPU, CUDAï¼‰
â”‚       â”œâ”€â”€ operators/     # ç®—å­å®ç°
â”‚       â”œâ”€â”€ graph/         # è®¡ç®—å›¾
â”‚       â”œâ”€â”€ runtime/       # è¿è¡Œæ—¶å¼•æ“
â”‚       â””â”€â”€ utils/         # å·¥å…·ç±»
â”œâ”€â”€ src/                   # æºæ–‡ä»¶å®ç°
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ backends/
â”‚   â”œâ”€â”€ operators/
â”‚   â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ runtime/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ tests/                 # æµ‹è¯•
â”œâ”€â”€ examples/              # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â””â”€â”€ CMakeLists.txt         # CMake é…ç½®æ–‡ä»¶
```

## æ„å»ºè¦æ±‚

### åŸºç¡€ä¾èµ–

- CMake 3.18+
- C++17 ç¼–è¯‘å™¨
  - MSVC 2017+ (Windows)
  - GCC 7+ (Linux)
  - Clang 5+ (macOS)

### å¯é€‰ä¾èµ–

#### ONNX æ¨¡å‹å¯¼å…¥æ”¯æŒ

å¦‚æœéœ€è¦å¯ç”¨ ONNX æ¨¡å‹å¯¼å…¥åŠŸèƒ½ï¼Œéœ€è¦å®‰è£… Protobufï¼š

**Windows (æ¨èä½¿ç”¨ vcpkg):**
```powershell
# 1. å®‰è£… vcpkg
git clone https://github.com/Microsoft/vcpkg.git C:\vcpkg
cd C:\vcpkg
.\bootstrap-vcpkg.bat

# 2. å®‰è£… protobuf
.\vcpkg install protobuf:x64-windows

# 3. é…ç½®ç¯å¢ƒå˜é‡ (å¯é€‰)
# å°† C:\vcpkg\installed\x64-windows\bin æ·»åŠ åˆ° PATH
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get update
sudo apt-get install -y libprotobuf-dev protobuf-compiler
```

**Linux (CentOS/RHEL):**
```bash
sudo yum install -y protobuf-devel protobuf-compiler
```

**macOS:**
```bash
brew install protobuf
```

## å¿«é€Ÿå¼€å§‹

### æ„å»ºé¡¹ç›®

#### Windows (åŸºç¡€æ„å»º)

```powershell
mkdir build
cd build
cmake ..
cmake --build . --config Release
```

#### Windows (ä½¿ç”¨ vcpkg + ONNX æ”¯æŒ)

```powershell
# æ–¹æ³• 1: ä½¿ç”¨ CMake é¢„è®¾ (æ¨è) - å…¨è‡ªåŠ¨é…ç½®
cmake --preset windows-vcpkg-release
cmake --build --preset windows-vcpkg-release

# æ–¹æ³• 2: æ‰‹åŠ¨æŒ‡å®šå·¥å…·é“¾ - å…¨è‡ªåŠ¨é…ç½®
cmake -B build -DCMAKE_TOOLCHAIN_FILE=C:\vcpkg\scripts\buildsystems\vcpkg.cmake -DMINI_INFER_ENABLE_ONNX=ON
cmake --build build --config Release
```

**ğŸš€ è‡ªåŠ¨åŒ–ç‰¹æ€§:**
- âœ… è‡ªåŠ¨ä¸‹è½½ ONNX proto æ–‡ä»¶
- âœ… è‡ªåŠ¨æ£€æµ‹ protoc ç‰ˆæœ¬å…¼å®¹æ€§
- âœ… è‡ªåŠ¨ç”Ÿæˆ C++ ä»£ç 
- âœ… æ— éœ€æ‰‹åŠ¨è¿è¡Œè„šæœ¬

#### Linux/macOS (åŸºç¡€æ„å»º)

```bash
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
make -j$(nproc)
```

#### Linux/macOS (ONNX æ”¯æŒ)

```bash
# æ–¹æ³• 1: ä½¿ç”¨ CMake é¢„è®¾ (æ¨è) - å…¨è‡ªåŠ¨é…ç½®
cmake --preset linux-onnx-release
cmake --build --preset linux-onnx-release

# æ–¹æ³• 2: æ‰‹åŠ¨é…ç½® - å…¨è‡ªåŠ¨é…ç½®
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Release -DMINI_INFER_ENABLE_ONNX=ON ..
make -j$(nproc)
```

**ğŸš€ è‡ªåŠ¨åŒ–ç‰¹æ€§:**
- âœ… è‡ªåŠ¨ä¸‹è½½ ONNX proto æ–‡ä»¶
- âœ… è‡ªåŠ¨æ£€æµ‹ protoc ç‰ˆæœ¬å…¼å®¹æ€§
- âœ… è‡ªåŠ¨ç”Ÿæˆ C++ ä»£ç 
- âœ… æ— éœ€æ‰‹åŠ¨è¿è¡Œè„šæœ¬

### CMake é¢„è®¾

é¡¹ç›®æä¾›äº†å¤šä¸ª CMake é¢„è®¾ï¼Œç®€åŒ–é…ç½®è¿‡ç¨‹ï¼š

#### å¯ç”¨é¢„è®¾

**Windows:**
- `windows-debug` - åŸºç¡€ Debug æ„å»º
- `windows-release` - åŸºç¡€ Release æ„å»º
- `windows-vcpkg-debug` - ä½¿ç”¨ vcpkg + ONNX çš„ Debug æ„å»º
- `windows-vcpkg-release` - ä½¿ç”¨ vcpkg + ONNX çš„ Release æ„å»º

**Linux:**
- `linux-debug` - åŸºç¡€ Debug æ„å»º
- `linux-release` - åŸºç¡€ Release æ„å»º
- `linux-onnx-debug` - å¯ç”¨ ONNX çš„ Debug æ„å»º
- `linux-onnx-release` - å¯ç”¨ ONNX çš„ Release æ„å»º

#### ä½¿ç”¨é¢„è®¾

```bash
# æŸ¥çœ‹å¯ç”¨é¢„è®¾
cmake --list-presets

# é…ç½®é¡¹ç›®
cmake --preset <preset-name>

# æ„å»ºé¡¹ç›®
cmake --build --preset <preset-name>

# è¿è¡Œæµ‹è¯•
ctest --preset <preset-name>
```

### è¿è¡Œæµ‹è¯•

```bash
# ä½¿ç”¨é¢„è®¾è¿è¡Œæµ‹è¯•
ctest --preset windows-vcpkg-release

# æˆ–ä¼ ç»Ÿæ–¹å¼
cd build
ctest --output-on-failure
```

### è¿è¡Œç¤ºä¾‹

```bash
# Windows
.\bin\Release\simple_inference.exe
.\bin\Release\build_graph.exe

# Linux/macOS
./bin/simple_inference
./bin/build_graph
```

## ç¼–è¯‘é€‰é¡¹

åœ¨è¿è¡Œ cmake æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹é€‰é¡¹ï¼š

```bash
cmake .. \
  -DMINI_INFER_BUILD_TESTS=ON \        # æ„å»ºæµ‹è¯•ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_BUILD_EXAMPLES=ON \     # æ„å»ºç¤ºä¾‹ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_BUILD_SHARED_LIBS=ON \  # æ„å»ºåŠ¨æ€åº“ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_ENABLE_CUDA=OFF \       # å¯ç”¨ CUDAï¼ˆé»˜è®¤ OFFï¼Œæœªæ¥æ”¯æŒï¼‰
  -DMINI_INFER_ENABLE_ONNX=ON \        # å¯ç”¨ ONNX æ¨¡å‹å¯¼å…¥ï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_ENABLE_PROFILING=ON \   # å¯ç”¨æ€§èƒ½åˆ†æï¼ˆé»˜è®¤ ONï¼‰
  -DMINI_INFER_ENABLE_LOGGING=ON       # å¯ç”¨æ—¥å¿—ï¼ˆé»˜è®¤ ONï¼‰
```

### ONNX ç›¸å…³é€‰é¡¹

- **`MINI_INFER_ENABLE_ONNX=ON`**: å¯ç”¨ ONNX æ¨¡å‹å¯¼å…¥æ”¯æŒ
  - éœ€è¦å…ˆå®‰è£… Protobuf ä¾èµ–
  - Windows æ¨èä½¿ç”¨ vcpkg å®‰è£…
  - å¦‚æœ Protobuf æœªæ‰¾åˆ°ï¼Œä¼šè‡ªåŠ¨ç¦ç”¨ ONNX æ”¯æŒå¹¶æ˜¾ç¤ºè­¦å‘Š

## ä½¿ç”¨ç¤ºä¾‹

### åˆ›å»ºå¼ é‡

```cpp
#include "mini_infer/core/tensor.h"

using namespace mini_infer;

// åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º [1, 3, 224, 224] çš„å¼ é‡
core::Shape shape({1, 3, 224, 224});
auto tensor = core::Tensor::create(shape, core::DataType::FLOAT32);

// è®¿é—®æ•°æ®
float* data = static_cast<float*>(tensor->data());
```

### æ„å»ºè®¡ç®—å›¾

```cpp
#include "mini_infer/graph/graph.h"

using namespace mini_infer;

// åˆ›å»ºå›¾
auto graph = std::make_shared<graph::Graph>();

// æ·»åŠ èŠ‚ç‚¹
auto input = graph->create_node("input");
auto conv1 = graph->create_node("conv1");
auto output = graph->create_node("output");

// è¿æ¥èŠ‚ç‚¹
graph->connect("input", "conv1");
graph->connect("conv1", "output");

// è®¾ç½®è¾“å…¥è¾“å‡º
graph->set_inputs({"input"});
graph->set_outputs({"output"});
```

### ONNX æ¨¡å‹å¯¼å…¥

```cpp
#include "mini_infer/importers/onnx_parser.h"
#include "mini_infer/runtime/runtime.h"

using namespace mini_infer;

int main() {
    // 1. è§£æ ONNX æ¨¡å‹
    importers::OnnxParser parser;
    parser.set_verbose(true);  // å¯ç”¨è¯¦ç»†æ—¥å¿—
    
    auto graph = parser.parse("model.onnx");
    if (!graph) {
        std::cerr << "Failed to parse ONNX model: " 
                  << parser.get_error() << std::endl;
        return 1;
    }
    
    // 2. åˆ›å»ºè¿è¡Œæ—¶
    runtime::Runtime runtime;
    if (!runtime.load_graph(std::move(graph))) {
        std::cerr << "Failed to load graph" << std::endl;
        return 1;
    }
    
    // 3. å‡†å¤‡è¾“å…¥æ•°æ®
    std::vector<float> input_data(1 * 3 * 224 * 224);
    // ... å¡«å……è¾“å…¥æ•°æ® ...
    
    // 4. æ‰§è¡Œæ¨ç†
    auto outputs = runtime.forward({input_data});
    
    // 5. å¤„ç†è¾“å‡º
    for (const auto& output : outputs) {
        std::cout << "Output size: " << output.size() << std::endl;
    }
    
    return 0;
}
```

**æ³¨æ„**: ONNX åŠŸèƒ½éœ€è¦åœ¨ç¼–è¯‘æ—¶å¯ç”¨ `-DMINI_INFER_ENABLE_ONNX=ON` å¹¶å®‰è£… Protobuf ä¾èµ–ã€‚

### è¿è¡Œæ¨ç†

```cpp
#include "mini_infer/runtime/engine.h"

using namespace mini_infer;

// é…ç½®å¼•æ“
runtime::EngineConfig config;
config.device_type = core::DeviceType::CPU;

// åˆ›å»ºå¼•æ“
runtime::Engine engine(config);

// æ„å»º
engine.build(graph);

// å‡†å¤‡è¾“å…¥
std::unordered_map<std::string, std::shared_ptr<core::Tensor>> inputs;
inputs["input"] = input_tensor;

// æ‰§è¡Œæ¨ç†
std::unordered_map<std::string, std::shared_ptr<core::Tensor>> outputs;
engine.forward(inputs, outputs);
```

## æ¶æ„è®¾è®¡

### ç»„ä»¶æ¶æ„å›¾

```mermaid
graph TB
    %% ç”¨æˆ·å±‚
    User[ç”¨æˆ· User]
    
    %% Runtime å±‚
    Runtime[Runtime è¿è¡Œæ—¶<br/>Engine, EngineConfig]
    
    %% ä¸­é—´å±‚ç»„ä»¶
    Graph[Graph è®¡ç®—å›¾<br/>Node, Graph]
    Backends[Backends åç«¯<br/>Backend, CPUBackend]
    Operators[Operators ç®—å­<br/>Operator, OpFactory]
    
    %% æ ¸å¿ƒå±‚
    Core[Core æ ¸å¿ƒ<br/>Tensor, Shape, DataType, Types, Allocator]
    
    %% å·¥å…·å±‚
    Utils[Utils å·¥å…·<br/>Logger]
    
    %% ä¾èµ–å…³ç³»
    User --> Runtime
    Runtime --> Graph
    Runtime --> Backends
    Runtime --> Operators
    Runtime --> Utils
    
    Graph --> Operators
    Graph --> Core
    
    Operators --> Backends
    Operators --> Core
    
    Backends --> Core
    
    %% æ ·å¼å®šä¹‰
    classDef userStyle fill:#e1f5ff,stroke:#01579b,stroke-width:2px
    classDef runtimeStyle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef componentStyle fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef coreStyle fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    classDef utilStyle fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    
    class User userStyle
    class Runtime runtimeStyle
    class Graph,Backends,Operators componentStyle
    class Core coreStyle
    class Utils utilStyle
```

### æ¨¡å—ä¾èµ–å…³ç³»

```mermaid
graph LR
    Runtime[Runtime<br/>è¿è¡Œæ—¶æ¨¡å—]
    Graph[Graph<br/>å›¾æ¨¡å—]
    Operators[Operators<br/>ç®—å­æ¨¡å—]
    Backends[Backends<br/>åç«¯æ¨¡å—]
    Core[Core<br/>æ ¸å¿ƒæ¨¡å—]
    Utils[Utils<br/>å·¥å…·æ¨¡å—]
    
    Runtime -->|ä¾èµ–| Graph
    Runtime -->|ä¾èµ–| Backends
    Runtime -->|ä¾èµ–| Operators
    Runtime -->|ä¾èµ–| Utils
    
    Graph -->|ä¾èµ–| Operators
    Graph -->|ä¾èµ–| Core
    
    Operators -->|ä¾èµ–| Backends
    Operators -->|ä¾èµ–| Core
    
    Backends -->|ä¾èµ–| Core
    
    style Runtime fill:#ffccbc,stroke:#bf360c
    style Graph fill:#c5cae9,stroke:#283593
    style Operators fill:#b2dfdb,stroke:#004d40
    style Backends fill:#d1c4e9,stroke:#4527a0
    style Core fill:#a5d6a7,stroke:#1b5e20
    style Utils fill:#fff9c4,stroke:#f57f17
```

### æ ¸å¿ƒæ¨¡å—

- **Core**: æä¾›åŸºç¡€æ•°æ®ç»“æ„ï¼ˆTensor, Shape, Allocatorï¼‰
- **Backends**: æŠ½è±¡çš„åç«¯æ¥å£ï¼Œæ”¯æŒä¸åŒç¡¬ä»¶åŠ é€Ÿ
- **Operators**: å„ç§ç®—å­çš„å®ç°ï¼ˆConv2D, Pooling, Activationç­‰ï¼‰
- **Graph**: è®¡ç®—å›¾çš„è¡¨ç¤ºå’Œä¼˜åŒ–
- **Runtime**: æ¨ç†å¼•æ“ï¼Œè´Ÿè´£æ‰§è¡Œè®¡ç®—å›¾
- **Utils**: æ—¥å¿—ã€æ€§èƒ½åˆ†æç­‰å·¥å…·

> ğŸ’¡ **æ›´å¤šæ¶æ„ç»†èŠ‚**: æŸ¥çœ‹ [å®Œæ•´ç»„ä»¶å›¾æ–‡æ¡£](docs/COMPONENT_DIAGRAM.md) äº†è§£è¯¦ç»†çš„ç»„ä»¶äº¤äº’ã€æ•°æ®æµå’Œæ‰©å±•ç‚¹

## å¼€å‘è·¯çº¿

- [x] åŸºç¡€æ¡†æ¶æ­å»º
- [x] CPU åç«¯å®ç°
- [ ] å¸¸ç”¨ç®—å­å®ç°ï¼ˆConv2D, ReLU, MaxPoolç­‰ï¼‰
- [ ] å›¾ä¼˜åŒ–ï¼ˆç®—å­èåˆã€å¸¸é‡æŠ˜å ï¼‰
- [ ] æ¨¡å‹æ ¼å¼æ”¯æŒï¼ˆONNXï¼‰
- [ ] CUDA åç«¯æ”¯æŒ
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆSIMDã€å¤šçº¿ç¨‹ï¼‰
- [ ] FP16 æ”¯æŒ
- [ ] INT8 é‡åŒ–æ”¯æŒ

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

MIT License

## ä½œè€…

James

## è‡´è°¢

æœ¬é¡¹ç›®å— TensorRT å¯å‘ï¼Œæ—¨åœ¨å­¦ä¹ å’Œç†è§£æ¨ç†æ¡†æ¶çš„è®¾è®¡åŸç†ã€‚

