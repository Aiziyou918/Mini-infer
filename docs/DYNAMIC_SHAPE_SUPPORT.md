# åŠ¨æ€ Shape æ”¯æŒè¯´æ˜

## ğŸ“Š å½“å‰æ”¯æŒæƒ…å†µ

Mini-Infer **å·²ç»æ”¯æŒ**åŸºç¡€çš„åŠ¨æ€ Shape æ¨æ–­ï¼Œä½†æœ‰ä¸€å®šé™åˆ¶ã€‚

---

## âœ… å·²å®ç°çš„åŠŸèƒ½

### 1. åŠ¨æ€ç»´åº¦è¯†åˆ«

```cpp
// Shape ç±»æ”¯æŒåŠ¨æ€ç»´åº¦ï¼ˆ-1ï¼‰
bool Shape::is_dynamic() const {
    for (int64_t dim : dims_) {
        if (dim < 0) {  // -1 è¡¨ç¤ºåŠ¨æ€ç»´åº¦
            return true;
        }
    }
    return false;
}
```

**ç¤ºä¾‹**ï¼š
```cpp
Shape static_shape({1, 3, 224, 224});    // é™æ€å½¢çŠ¶
Shape dynamic_shape({-1, 3, 224, 224});  // åŠ¨æ€ batch size

assert(!static_shape.is_dynamic());  // false
assert(dynamic_shape.is_dynamic());  // true
```

### 2. ONNX åŠ¨æ€ç»´åº¦å¯¼å…¥

ä» ONNX æ¨¡å‹å¯¼å…¥æ—¶è‡ªåŠ¨è¯†åˆ«åŠ¨æ€ç»´åº¦ï¼š

```cpp
// src/importers/model_importer.cpp
if (dim.has_dim_param()) {
    // Dynamic dimension (e.g., batch size)
    dims.push_back(-1);
    ctx.log_info("  Dynamic dimension: " + dim.dim_param());
}
```

**ONNX æ¨¡å‹ç¤ºä¾‹**ï¼š
```protobuf
input {
  name: "input"
  type {
    tensor_type {
      shape {
        dim { dim_param: "batch" }  # åŠ¨æ€ç»´åº¦
        dim { dim_value: 3 }        # å›ºå®šç»´åº¦
        dim { dim_value: 224 }
        dim { dim_value: 224 }
      }
    }
  }
}
```

**å¯¼å…¥ç»“æœ**ï¼š
```cpp
// è§£æä¸º Shape([-1, 3, 224, 224])
```

### 3. Build æ—¶ä½¿ç”¨é»˜è®¤å€¼

åœ¨ `Engine::build()` é˜¶æ®µï¼ŒåŠ¨æ€ç»´åº¦ä½¿ç”¨é»˜è®¤å€¼ï¼ˆbatch=1ï¼‰ï¼š

```cpp
// src/importers/model_importer.cpp
for (size_t j = 0; j < input_shape.ndim(); ++j) {
    int64_t dim = input_shape[j];
    if (dim < 0) {
        // Use batch size 1 as default for dynamic dimensions
        concrete_dims.push_back(1);
    } else {
        concrete_dims.push_back(dim);
    }
}
```

**åŸå› **ï¼š
- Shape æ¨æ–­éœ€è¦å…·ä½“çš„ç»´åº¦å€¼
- å†…å­˜è§„åˆ’éœ€è¦è®¡ç®—å‡†ç¡®çš„ tensor size
- ä½¿ç”¨ batch=1 ä½œä¸ºåˆç†çš„é»˜è®¤å€¼

### 4. Forward æ—¶æ”¯æŒä¸åŒ Batch Size

åœ¨ `Engine::forward()` æ—¶å…è®¸ä¸åŒçš„ batch sizeï¼š

```cpp
// src/runtime/engine.cpp - validate_input_shapes()
for (size_t i = 0; i < expected_shape.ndim(); ++i) {
    // Skip dynamic dimensions (-1) or batch dimension (index 0)
    if (expected_shape[i] < 0 || i == 0) continue;  // â† è·³è¿‡ batch ç»´åº¦
    
    if (expected_shape[i] != actual_shape[i]) {
        // æŠ¥é”™ï¼šå…¶ä»–ç»´åº¦å¿…é¡»åŒ¹é…
    }
}
```

**ç¤ºä¾‹**ï¼š
```cpp
// Build æ—¶ä½¿ç”¨é»˜è®¤ batch=1
engine.build(graph);  // å†…éƒ¨ä½¿ç”¨ [1, 3, 224, 224]

// Forward æ—¶å¯ä»¥ä½¿ç”¨ä¸åŒ batch
auto input_batch1 = std::make_shared<Tensor>(
    Shape({1, 3, 224, 224}),  // âœ… batch=1
    DataType::FLOAT32
);
engine.forward({{"input", input_batch1}});

auto input_batch8 = std::make_shared<Tensor>(
    Shape({8, 3, 224, 224}),  // âœ… batch=8 (å…è®¸)
    DataType::FLOAT32
);
engine.forward({{"input", input_batch8}});
```

---

## âš ï¸ å½“å‰é™åˆ¶

### 1. åªæ”¯æŒ Batch ç»´åº¦åŠ¨æ€

**æ”¯æŒ**ï¼š
```cpp
Shape({-1, 3, 224, 224});  // âœ… åŠ¨æ€ batch size
```

**ä¸æ”¯æŒ**ï¼š
```cpp
Shape({1, 3, -1, -1});     // âŒ åŠ¨æ€ H/Wï¼ˆæœªå®Œå…¨æµ‹è¯•ï¼‰
Shape({1, -1, 224, 224});  // âŒ åŠ¨æ€ channelï¼ˆæœªå®Œå…¨æµ‹è¯•ï¼‰
```

**åŸå› **ï¼š
- å½“å‰åªåœ¨ç¬¬ 0 ç»´ï¼ˆbatchï¼‰åšäº†ç‰¹æ®Šå¤„ç†
- å…¶ä»–åŠ¨æ€ç»´åº¦éœ€è¦æ›´å¤æ‚çš„å½¢çŠ¶æ¨æ–­é€»è¾‘

### 2. å†…å­˜è§„åˆ’åŸºäºé»˜è®¤ Batch

å†…å­˜è§„åˆ’åœ¨ build é˜¶æ®µå®Œæˆï¼Œä½¿ç”¨ batch=1ï¼š

```cpp
// Build æ—¶
engine.build(graph);  // ä½¿ç”¨ [1, 3, 224, 224] è®¡ç®—å†…å­˜

// å†…å­˜è§„åˆ’ç»“æœ
Memory plan: 150KB (based on batch=1)
```

**å½±å“**ï¼š
- Forward æ—¶ä½¿ç”¨ batch=8ï¼Œå®é™…éœ€è¦å†…å­˜ = 150KB * 8 = 1200KB
- å†…å­˜æ± å¤§å°æ˜¯æŒ‰ batch=1 åˆ†é…çš„ï¼ˆå¯èƒ½éœ€è¦é‡æ–°åˆ†é…ï¼‰

### 3. æ²¡æœ‰è¿è¡Œæ—¶é‡æ–°æ¨æ–­

Forward æ—¶ä¸ä¼šé‡æ–°æ‰§è¡Œ shape æ¨æ–­ï¼š

```cpp
// Forward æ—¶
engine.forward({{"input", input_batch8}});  
// âŒ ä¸ä¼šé‡æ–°æ¨æ–­æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡ºå½¢çŠ¶
// âœ… ç›´æ¥ä½¿ç”¨ build æ—¶æ¨æ–­çš„å½¢çŠ¶ï¼ˆå¯èƒ½å¯¼è‡´å°ºå¯¸ä¸åŒ¹é…ï¼‰
```

---

## ğŸ“‹ æ”¯æŒçº§åˆ«æ€»ç»“

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|-----|------|------|
| **è¯†åˆ«åŠ¨æ€ç»´åº¦** | âœ… å®Œå…¨æ”¯æŒ | `Shape::is_dynamic()` |
| **ONNX åŠ¨æ€ç»´åº¦å¯¼å…¥** | âœ… å®Œå…¨æ”¯æŒ | è‡ªåŠ¨è§£æ `dim_param` |
| **Build æ—¶é»˜è®¤å€¼** | âœ… å®Œå…¨æ”¯æŒ | åŠ¨æ€ç»´åº¦ä½¿ç”¨ 1 |
| **Forward æ—¶éªŒè¯** | âœ… éƒ¨åˆ†æ”¯æŒ | è·³è¿‡ batch ç»´åº¦æ£€æŸ¥ |
| **åŠ¨æ€ Batch** | âœ… åŸºç¡€æ”¯æŒ | å…è®¸ä¸åŒ batch size |
| **åŠ¨æ€ H/W/C** | âš ï¸ æœªæµ‹è¯• | ç†è®ºå¯è¡Œï¼ŒæœªéªŒè¯ |
| **è¿è¡Œæ—¶é‡æ¨æ–­** | âŒ ä¸æ”¯æŒ | Forward ä¸é‡æ–°æ¨æ–­å½¢çŠ¶ |
| **åŠ¨æ€å†…å­˜åˆ†é…** | âš ï¸ éƒ¨åˆ†æ”¯æŒ | å¯èƒ½éœ€è¦é‡æ–°åˆ†é… |

---

## ğŸ¯ ä½¿ç”¨å»ºè®®

### åœºæ™¯ 1: å›ºå®šè¾“å…¥å°ºå¯¸ï¼ˆæ¨èï¼‰

```cpp
// ONNX æ¨¡å‹æœ‰åŠ¨æ€ç»´åº¦
// input: [-1, 3, 224, 224]

// Build æ—¶ä½¿ç”¨é»˜è®¤ batch=1
engine.build(graph);

// Forward æ—¶ä½¿ç”¨ç›¸åŒå°ºå¯¸
auto input = std::make_shared<Tensor>(
    Shape({1, 3, 224, 224}),  // ä¸ build æ—¶ä¸€è‡´
    DataType::FLOAT32
);
engine.forward({{"input", input}});
```

**ä¼˜ç‚¹**ï¼š
- âœ… æ€§èƒ½æœ€ä¼˜
- âœ… å†…å­˜è§„åˆ’å‡†ç¡®
- âœ… æ— é¢å¤–å¼€é”€

### åœºæ™¯ 2: å˜åŒ–çš„ Batch Size

```cpp
// Build æ—¶ä½¿ç”¨é»˜è®¤ batch=1
engine.build(graph);

// Forward æ—¶ä½¿ç”¨ä¸åŒ batch
for (int batch : {1, 2, 4, 8}) {
    auto input = std::make_shared<Tensor>(
        Shape({batch, 3, 224, 224}),
        DataType::FLOAT32
    );
    engine.forward({{"input", input}});
}
```

**ä¼˜ç‚¹**ï¼š
- âœ… çµæ´»æ€§é«˜
- âœ… æ”¯æŒåŠ¨æ€ batch

**ç¼ºç‚¹**ï¼š
- âš ï¸ å†…å­˜å¯èƒ½éœ€è¦é‡æ–°åˆ†é…
- âš ï¸ å¯èƒ½æœ‰æ€§èƒ½æŸå¤±

### åœºæ™¯ 3: å®Œå…¨åŠ¨æ€å½¢çŠ¶ï¼ˆä¸æ¨èï¼‰

```cpp
// ä»»æ„å°ºå¯¸è¾“å…¥
auto input1 = std::make_shared<Tensor>(Shape({1, 3, 224, 224}));
auto input2 = std::make_shared<Tensor>(Shape({4, 3, 512, 512}));
```

**ç°çŠ¶**ï¼š
- âŒ ä¸æ”¯æŒè¿è¡Œæ—¶é‡æ¨æ–­
- âŒ å¯èƒ½å¯¼è‡´é”™è¯¯æˆ–å´©æºƒ

---

## ğŸš€ TensorRT å¯¹æ¯”

### TensorRT çš„åŠ¨æ€ Shape æ”¯æŒ

```cpp
// TensorRT API
builder->setMaxBatchSize(32);
profile->setDimensions("input", 
    OptProfileSelector::kMIN, Dims4{1, 3, 224, 224});
profile->setDimensions("input", 
    OptProfileSelector::kMAX, Dims4{32, 3, 224, 224});
profile->setDimensions("input", 
    OptProfileSelector::kOPT, Dims4{8, 3, 224, 224});
```

**TensorRT ç‰¹æ€§**ï¼š
1. âœ… å®šä¹‰å¤šä¸ª Optimization Profile
2. âœ… æŒ‡å®š Min/Max/Opt èŒƒå›´
3. âœ… è¿è¡Œæ—¶åœ¨èŒƒå›´å†…åŠ¨æ€åˆ†é…
4. âœ… å®Œæ•´çš„åŠ¨æ€ç»´åº¦æ”¯æŒï¼ˆä»»æ„ç»´åº¦ï¼‰

### Mini-Infer vs TensorRT

| ç‰¹æ€§ | Mini-Infer | TensorRT |
|-----|-----------|----------|
| åŠ¨æ€ batch | âœ… åŸºç¡€æ”¯æŒ | âœ… å®Œå…¨æ”¯æŒ |
| åŠ¨æ€ H/W | âš ï¸ æœªæµ‹è¯• | âœ… å®Œå…¨æ”¯æŒ |
| Optimization Profile | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| è¿è¡Œæ—¶é‡æ¨æ–­ | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| å†…å­˜æ± åŠ¨æ€è°ƒæ•´ | âš ï¸ æœ‰é™ | âœ… å®Œå…¨æ”¯æŒ |

---

## ğŸ“ æœªæ¥æ”¹è¿›æ–¹å‘

### ä¼˜å…ˆçº§ 1: è¿è¡Œæ—¶ Shape é‡æ¨æ–­

```cpp
class Engine {
public:
    // æ–°å¢ï¼šè¿è¡Œæ—¶å½¢çŠ¶æ¨æ–­
    Status infer_shapes_runtime(
        const std::map<std::string, std::shared_ptr<core::Tensor>>& inputs
    ) {
        // åŸºäºå®é™…è¾“å…¥é‡æ–°æ¨æ–­æ‰€æœ‰èŠ‚ç‚¹çš„è¾“å‡ºå½¢çŠ¶
        // æ›´æ–°å†…å­˜åˆ†é…
    }
    
    TensorMap forward(const TensorMap& inputs) override {
        // 1. æ£€æŸ¥è¾“å…¥å½¢çŠ¶æ˜¯å¦å˜åŒ–
        if (input_shape_changed(inputs)) {
            // 2. é‡æ–°æ¨æ–­å½¢çŠ¶
            infer_shapes_runtime(inputs);
            // 3. é‡æ–°åˆ†é…å†…å­˜ï¼ˆå¦‚éœ€è¦ï¼‰
            reallocate_if_needed();
        }
        // 4. æ‰§è¡Œæ¨ç†
        return execute(inputs);
    }
};
```

### ä¼˜å…ˆçº§ 2: Optimization Profile

```cpp
struct OptimizationProfile {
    std::string input_name;
    Shape min_shape;
    Shape max_shape;
    Shape opt_shape;
};

class Engine {
public:
    void add_optimization_profile(const OptimizationProfile& profile);
    void set_active_profile(int index);
};
```

### ä¼˜å…ˆçº§ 3: åŠ¨æ€å†…å­˜æ± 

```cpp
class DynamicMemoryPool {
public:
    // æ ¹æ®å®é™…å½¢çŠ¶åŠ¨æ€è°ƒæ•´å†…å­˜æ± å¤§å°
    void resize(size_t new_size);
    
    // è®°å½•æœ€å¤§ä½¿ç”¨é‡
    size_t peak_usage() const;
};
```

---

## ğŸ§ª æµ‹è¯•ç¤ºä¾‹

### æµ‹è¯• 1: åŠ¨æ€ Batch æ¨ç†

```cpp
#include "mini_infer/importers/onnx_parser.h"
#include "mini_infer/runtime/engine.h"

int main() {
    // 1. åŠ è½½æ¨¡å‹ï¼ˆå‡è®¾æœ‰åŠ¨æ€ batchï¼‰
    OnnxParser parser;
    auto graph = parser.parse_from_file("model.onnx");
    // input shape: [-1, 3, 224, 224]
    
    // 2. Build engineï¼ˆä½¿ç”¨é»˜è®¤ batch=1ï¼‰
    EngineConfig config;
    Engine engine(config);
    engine.build(graph);
    
    // 3. æµ‹è¯•ä¸åŒ batch size
    for (int batch : {1, 2, 4, 8}) {
        auto input = std::make_shared<Tensor>(
            Shape({batch, 3, 224, 224}),
            DataType::FLOAT32
        );
        
        std::cout << "Testing batch=" << batch << std::endl;
        auto outputs = engine.forward({{"input", input}});
        
        // éªŒè¯è¾“å‡ºå½¢çŠ¶
        for (const auto& [name, tensor] : outputs) {
            std::cout << "  " << name << ": " 
                     << tensor->shape().to_string() << std::endl;
        }
    }
    
    return 0;
}
```

### æµ‹è¯• 2: å½¢çŠ¶éªŒè¯

```cpp
TEST(DynamicShapeTest, BatchDimensionAllowed) {
    // Build æ—¶: [1, 3, 224, 224]
    auto graph = create_test_graph();
    Engine engine(config);
    engine.build(graph);
    
    // Forward æ—¶: [8, 3, 224, 224]
    auto input = std::make_shared<Tensor>(
        Shape({8, 3, 224, 224}),
        DataType::FLOAT32
    );
    
    auto outputs = engine.forward({{"input", input}});
    EXPECT_TRUE(outputs.size() > 0);  // âœ… åº”è¯¥æˆåŠŸ
}

TEST(DynamicShapeTest, OtherDimensionsMustMatch) {
    // Build æ—¶: [1, 3, 224, 224]
    auto graph = create_test_graph();
    Engine engine(config);
    engine.build(graph);
    
    // Forward æ—¶: [1, 3, 256, 256] (H/W ä¸åŒ¹é…)
    auto input = std::make_shared<Tensor>(
        Shape({1, 3, 256, 256}),
        DataType::FLOAT32
    );
    
    auto outputs = engine.forward({{"input", input}});
    EXPECT_TRUE(outputs.empty());  // âŒ åº”è¯¥å¤±è´¥
}
```

---

## âœ… æ€»ç»“

### å½“å‰çŠ¶æ€

**Mini-Infer å·²ç»æ”¯æŒåŸºç¡€çš„åŠ¨æ€ Shape æ¨æ–­**ï¼š

âœ… **æ”¯æŒ**ï¼š
- åŠ¨æ€ç»´åº¦è¯†åˆ«ï¼ˆ-1ï¼‰
- ONNX åŠ¨æ€ç»´åº¦å¯¼å…¥
- åŠ¨æ€ batch sizeï¼ˆç¬¬ 0 ç»´ï¼‰
- Build æ—¶ä½¿ç”¨é»˜è®¤å€¼
- Forward æ—¶ batch ç»´åº¦çµæ´»

âš ï¸ **é™åˆ¶**ï¼š
- åªå……åˆ†æµ‹è¯•äº†åŠ¨æ€ batch
- æ²¡æœ‰è¿è¡Œæ—¶é‡æ¨æ–­
- å†…å­˜è§„åˆ’åŸºäºé»˜è®¤å€¼
- ä¸æ”¯æŒ Optimization Profile

### æ¨èç”¨æ³•

```cpp
// âœ… æ¨èï¼šå›ºå®šå°ºå¯¸æˆ–åªå˜åŒ– batch
engine.build(graph);  // batch=1
engine.forward({{"input", input_batch1}});  // OK
engine.forward({{"input", input_batch8}});  // OK

// âš ï¸ è°¨æ…ï¼šå˜åŒ–å…¶ä»–ç»´åº¦
engine.forward({{"input", input_different_hw}});  // å¯èƒ½å¤±è´¥

// âŒ ä¸æ¨èï¼šå®Œå…¨åŠ¨æ€
// éœ€è¦å®ç°è¿è¡Œæ—¶é‡æ¨æ–­
```

### ä¸ TensorRT å·®è·

Mini-Infer æä¾›äº†**åŸºç¡€çš„åŠ¨æ€ Shape æ”¯æŒ**ï¼Œé€‚åˆï¼š
- å›ºå®šè¾“å…¥å°ºå¯¸çš„åœºæ™¯
- åªéœ€è¦åŠ¨æ€ batch çš„åœºæ™¯

å¦‚éœ€å®Œæ•´çš„åŠ¨æ€ Shape æ”¯æŒï¼ˆå¦‚ TensorRTï¼‰ï¼Œéœ€è¦å®ç°ï¼š
1. è¿è¡Œæ—¶ shape é‡æ¨æ–­
2. Optimization Profile æœºåˆ¶
3. åŠ¨æ€å†…å­˜æ± ç®¡ç†

è¿™äº›åŠŸèƒ½å¯ä»¥ä½œä¸ºæœªæ¥çš„æ”¹è¿›æ–¹å‘ï¼ğŸš€


