# Static Memory Planner - è®¾è®¡æ–‡æ¡£

## æ¦‚è¿°

å®ç°TensorRTé£æ ¼çš„é™æ€å†…å­˜è§„åˆ’ï¼Œé€šè¿‡åˆ†æTensorç”Ÿå‘½å‘¨æœŸï¼Œè®©ç”Ÿå‘½å‘¨æœŸä¸é‡å çš„Tensorå¤ç”¨åŒä¸€å—å†…å­˜ï¼Œå¤§å¹…é™ä½å†…å­˜å ç”¨ã€‚

---

## é—®é¢˜åˆ†æ

### å½“å‰çŠ¶æ€ï¼ˆæœªä¼˜åŒ–ï¼‰
```
Layer1_Out: [====ç”Ÿå‘½å‘¨æœŸ====]     å ç”¨ 1MB
Layer2_Out:          [====ç”Ÿå‘½å‘¨æœŸ====]     å ç”¨ 0.5MB
Layer3_Out:                   [====ç”Ÿå‘½å‘¨æœŸ====]     å ç”¨ 0.8MB

æ€»å†…å­˜å ç”¨: 1MB + 0.5MB + 0.8MB = 2.3MB
```

### ä¼˜åŒ–åï¼ˆé™æ€å†…å­˜è§„åˆ’ï¼‰
```
Memory Pool A: [====Layer1_Out====][====Layer3_Out====]
Memory Pool B:          [====Layer2_Out====]

æ€»å†…å­˜å ç”¨: max(1MB, 0.8MB) + 0.5MB = 1.5MB
èŠ‚çœ: 0.8MB (35%)
```

---

## TensorRT å†…å­˜è§„åˆ’ç­–ç•¥

### 1. **ç”Ÿå‘½å‘¨æœŸåˆ†æï¼ˆLiveness Analysisï¼‰**
- ç¡®å®šæ¯ä¸ªTensorçš„ç”Ÿå‘½å‘¨æœŸï¼šä»åˆ›å»ºåˆ°æœ€åä¸€æ¬¡ä½¿ç”¨
- ä½¿ç”¨æ‹“æ‰‘æ’åºç¡®å®šæ‰§è¡Œé¡ºåº
- æ ‡è®°æ¯ä¸ªTensorçš„ `birth_time` å’Œ `death_time`

### 2. **å†…å­˜åˆ†é…ç®—æ³•**
TensorRTä½¿ç”¨**è´ªå¿ƒç€è‰²ç®—æ³•ï¼ˆGreedy Coloringï¼‰**ï¼š
- å°†Tensorçœ‹ä½œå›¾çš„èŠ‚ç‚¹
- ç”Ÿå‘½å‘¨æœŸé‡å çš„Tensorä¹‹é—´æœ‰è¾¹ï¼ˆå†²çªï¼‰
- å›¾ç€è‰²é—®é¢˜ï¼šç”¨æœ€å°‘çš„é¢œè‰²ç»™èŠ‚ç‚¹ç€è‰²ï¼Œç›¸é‚»èŠ‚ç‚¹é¢œè‰²ä¸åŒ
- æ¯ç§é¢œè‰²å¯¹åº”ä¸€ä¸ªå†…å­˜æ± 

### 3. **å†…å­˜æ± ç®¡ç†**
- æ¯ä¸ªå†…å­˜æ± æ˜¯ä¸€å—è¿ç»­å†…å­˜
- æ± çš„å¤§å° = è¯¥æ± ä¸­æœ€å¤§Tensorçš„å¤§å°
- Tensoråœ¨è¿è¡Œæ—¶ä»å¯¹åº”çš„æ± ä¸­è·å–å†…å­˜ï¼ˆoffset=0ï¼‰

---

## å®ç°æ–¹æ¡ˆ

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Memory Planner                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. Liveness Analyzer                                       â”‚
â”‚     â”œâ”€ Topological Sort                                     â”‚
â”‚     â”œâ”€ Compute Birth/Death Time                             â”‚
â”‚     â””â”€ Build Interference Graph                             â”‚
â”‚                                                             â”‚
â”‚  2. Memory Allocator (Greedy Coloring)                      â”‚
â”‚     â”œâ”€ Graph Coloring Algorithm                             â”‚
â”‚     â”œâ”€ Pool Assignment                                      â”‚
â”‚     â””â”€ Memory Layout Optimization                           â”‚
â”‚                                                             â”‚
â”‚  3. Memory Pool Manager                                     â”‚
â”‚     â”œâ”€ Pool Creation                                        â”‚
â”‚     â”œâ”€ Tensor Binding                                       â”‚
â”‚     â””â”€ Runtime Memory Access                                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒæ•°æ®ç»“æ„

```cpp
// Tensorç”Ÿå‘½å‘¨æœŸä¿¡æ¯
struct TensorLifetime {
    std::string name;
    size_t size_bytes;
    int birth_time;   // åˆ›å»ºæ—¶é—´ï¼ˆæ‹“æ‰‘åºå·ï¼‰
    int death_time;   // æœ€åä½¿ç”¨æ—¶é—´
    int pool_id;      // åˆ†é…çš„å†…å­˜æ± ID
};

// å†…å­˜æ± 
struct MemoryPool {
    int pool_id;
    size_t size_bytes;  // æ± å¤§å°ï¼ˆè¯¥æ± ä¸­æœ€å¤§Tensorçš„å¤§å°ï¼‰
    std::vector<std::string> tensors;  // ä½¿ç”¨è¯¥æ± çš„Tensoråˆ—è¡¨
};

// å†…å­˜è§„åˆ’ç»“æœ
struct MemoryPlan {
    std::vector<MemoryPool> pools;
    std::unordered_map<std::string, int> tensor_to_pool;
    size_t total_memory;
    size_t original_memory;
    float memory_saving_ratio;
};
```

---

## ç®—æ³•è¯¦è§£

### ç®—æ³•1ï¼šç”Ÿå‘½å‘¨æœŸåˆ†æ

```cpp
LivenessAnalyzer::analyze(Graph* graph) {
    // Step 1: æ‹“æ‰‘æ’åºï¼Œç¡®å®šæ‰§è¡Œé¡ºåº
    vector<Node*> topo_order = graph->topological_sort();
    
    // Step 2: ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ†é…æ—¶é—´æˆ³
    for (int i = 0; i < topo_order.size(); ++i) {
        node_time[topo_order[i]] = i;
    }
    
    // Step 3: è®¡ç®—æ¯ä¸ªTensorçš„ç”Ÿå‘½å‘¨æœŸ
    for (auto& tensor : all_tensors) {
        // Birth time: ç”Ÿäº§è¯¥Tensorçš„èŠ‚ç‚¹çš„æ—¶é—´
        tensor.birth_time = node_time[tensor.producer];
        
        // Death time: æœ€åä¸€ä¸ªæ¶ˆè´¹è¯¥Tensorçš„èŠ‚ç‚¹çš„æ—¶é—´
        tensor.death_time = 0;
        for (auto& consumer : tensor.consumers) {
            tensor.death_time = max(tensor.death_time, node_time[consumer]);
        }
    }
    
    return lifetimes;
}
```

### ç®—æ³•2ï¼šå†²çªå›¾æ„å»º

```cpp
InterferenceGraph build_interference_graph(vector<TensorLifetime>& lifetimes) {
    InterferenceGraph graph;
    
    // æ·»åŠ æ‰€æœ‰Tensorä½œä¸ºèŠ‚ç‚¹
    for (auto& lt : lifetimes) {
        graph.add_node(lt.name);
    }
    
    // æ·»åŠ è¾¹ï¼šç”Ÿå‘½å‘¨æœŸé‡å çš„Tensorä¹‹é—´æœ‰è¾¹
    for (int i = 0; i < lifetimes.size(); ++i) {
        for (int j = i + 1; j < lifetimes.size(); ++j) {
            if (lifetimes_overlap(lifetimes[i], lifetimes[j])) {
                graph.add_edge(lifetimes[i].name, lifetimes[j].name);
            }
        }
    }
    
    return graph;
}

bool lifetimes_overlap(TensorLifetime& a, TensorLifetime& b) {
    // ä¸¤ä¸ªåŒºé—´é‡å çš„æ¡ä»¶
    return !(a.death_time < b.birth_time || b.death_time < a.birth_time);
}
```

### ç®—æ³•3ï¼šè´ªå¿ƒç€è‰²ï¼ˆå†…å­˜åˆ†é…ï¼‰

```cpp
MemoryPlan greedy_coloring(InterferenceGraph& graph, 
                           vector<TensorLifetime>& lifetimes) {
    // æŒ‰å¤§å°é™åºæ’åºï¼ˆå¤§çš„Tensorä¼˜å…ˆåˆ†é…ï¼‰
    sort(lifetimes.begin(), lifetimes.end(), 
         [](auto& a, auto& b) { return a.size_bytes > b.size_bytes; });
    
    MemoryPlan plan;
    
    for (auto& tensor : lifetimes) {
        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„é¢œè‰²ï¼ˆå†…å­˜æ± ï¼‰
        int pool_id = find_available_pool(tensor, graph, plan);
        
        if (pool_id == -1) {
            // éœ€è¦æ–°çš„å†…å­˜æ± 
            pool_id = plan.pools.size();
            plan.pools.push_back(MemoryPool{pool_id, tensor.size_bytes, {tensor.name}});
        } else {
            // ä½¿ç”¨ç°æœ‰å†…å­˜æ± 
            plan.pools[pool_id].tensors.push_back(tensor.name);
            plan.pools[pool_id].size_bytes = max(plan.pools[pool_id].size_bytes, 
                                                   tensor.size_bytes);
        }
        
        plan.tensor_to_pool[tensor.name] = pool_id;
    }
    
    return plan;
}

int find_available_pool(TensorLifetime& tensor, 
                        InterferenceGraph& graph,
                        MemoryPlan& plan) {
    for (int pool_id = 0; pool_id < plan.pools.size(); ++pool_id) {
        bool can_use = true;
        
        // æ£€æŸ¥è¯¥æ± ä¸­çš„æ‰€æœ‰Tensoræ˜¯å¦ä¸å½“å‰Tensorå†²çª
        for (auto& other_tensor : plan.pools[pool_id].tensors) {
            if (graph.has_edge(tensor.name, other_tensor)) {
                can_use = false;
                break;
            }
        }
        
        if (can_use) {
            return pool_id;
        }
    }
    
    return -1;  // æ²¡æœ‰å¯ç”¨çš„æ± 
}
```

---

## ä¼˜åŒ–æŠ€å·§

### 1. **In-place Operations**
æŸäº›æ“ä½œå¯ä»¥åŸåœ°ä¿®æ”¹è¾“å…¥ï¼ˆå¦‚ReLUï¼‰ï¼Œä¸éœ€è¦é¢å¤–å†…å­˜ï¼š
```cpp
if (is_inplace_op(node)) {
    output_tensor.pool_id = input_tensor.pool_id;
    output_tensor.offset = input_tensor.offset;
}
```

### 2. **Persistent Tensors**
æŸäº›Tensoréœ€è¦åœ¨æ•´ä¸ªæ¨ç†è¿‡ç¨‹ä¸­ä¿æŒï¼ˆå¦‚æƒé‡ã€è¾“å…¥ã€è¾“å‡ºï¼‰ï¼š
```cpp
if (is_persistent(tensor)) {
    // åˆ†é…ç‹¬ç«‹å†…å­˜ï¼Œä¸å‚ä¸å¤ç”¨
    tensor.pool_id = PERSISTENT_POOL;
}
```

### 3. **Alignment**
å†…å­˜å¯¹é½ä»¥æé«˜è®¿é—®æ•ˆç‡ï¼š
```cpp
size_t aligned_size = align_up(tensor.size_bytes, 256);  // 256å­—èŠ‚å¯¹é½
```

---

## æ€§èƒ½é¢„æœŸ

### LeNet-5 ç¤ºä¾‹
```
æœªä¼˜åŒ–:
  Conv1_out: 6x12x12 = 864 bytes
  Pool1_out: 6x6x6 = 216 bytes
  Conv2_out: 16x4x4 = 256 bytes
  Pool2_out: 16x2x2 = 64 bytes
  FC1_out: 120 bytes
  FC2_out: 84 bytes
  FC3_out: 10 bytes
  æ€»è®¡: ~1.6KB

ä¼˜åŒ–å:
  Pool A: max(864, 256, 120, 10) = 864 bytes
  Pool B: max(216, 64, 84) = 216 bytes
  æ€»è®¡: ~1.1KB
  èŠ‚çœ: 31%
```

### å¤§å‹ç½‘ç»œï¼ˆå¦‚ResNet-50ï¼‰
- æœªä¼˜åŒ–: ~200MB
- ä¼˜åŒ–å: ~50MB
- **èŠ‚çœ: 75%** ğŸ‰

---

## å®ç°è®¡åˆ’

### Phase 1: æ ¸å¿ƒæ¡†æ¶
- [ ] `MemoryPlanner` åŸºç±»
- [ ] `LivenessAnalyzer` ç”Ÿå‘½å‘¨æœŸåˆ†æ
- [ ] `TensorLifetime` æ•°æ®ç»“æ„

### Phase 2: å†…å­˜åˆ†é…
- [ ] `InterferenceGraph` å†²çªå›¾
- [ ] `GreedyColoringAllocator` è´ªå¿ƒç€è‰²ç®—æ³•
- [ ] `MemoryPool` å†…å­˜æ± ç®¡ç†

### Phase 3: é›†æˆåˆ°Runtime
- [ ] ä¿®æ”¹ `Engine::build()` è°ƒç”¨å†…å­˜è§„åˆ’
- [ ] ä¿®æ”¹ `Tensor` ç±»æ”¯æŒå…±äº«å†…å­˜
- [ ] è¿è¡Œæ—¶å†…å­˜ç»‘å®š

### Phase 4: ä¼˜åŒ–å’Œæµ‹è¯•
- [ ] In-placeæ“ä½œä¼˜åŒ–
- [ ] å†…å­˜å¯¹é½ä¼˜åŒ–
- [ ] æ€§èƒ½æµ‹è¯•å’ŒéªŒè¯

---

## å‚è€ƒèµ„æ–™

1. **TensorRT Documentation**: Memory Management
2. **TFLite**: Arena Planner
3. **ONNX Runtime**: Memory Pattern Optimization
4. **è®ºæ–‡**: "Optimizing Memory Allocation for Deep Neural Networks"

---

## ä¸‹ä¸€æ­¥

å¼€å§‹å®ç° Phase 1: æ ¸å¿ƒæ¡†æ¶ï¼
