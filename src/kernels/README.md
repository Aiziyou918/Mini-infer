# Mini-Infer Kernel Layer

## ğŸ“– æ¦‚è¿°

Kernelå±‚æ˜¯Mini-Inferçš„è®¡ç®—æ ¸å¿ƒï¼Œæä¾›é«˜æ€§èƒ½çš„ç®—å­å®ç°ã€‚è®¾è®¡å‚è€ƒTensorRTçš„Pluginæ¶æ„ï¼Œæ”¯æŒå¤šBackendï¼ˆCPU/GPUï¼‰å’Œçµæ´»æ‰©å±•ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Operator Layer               â”‚
â”‚   (Conv2D, Linear, ReLU, ...)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Kernel Interface             â”‚
â”‚   (GEMMKernel, Im2ColKernel, ...)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CPU Kernels  â”‚  â”‚  CUDA Kernels â”‚
â”‚              â”‚  â”‚   (æœªæ¥)       â”‚
â”‚ - gemm_cpu   â”‚  â”‚ - gemm_cuda   â”‚
â”‚ - im2col_cpu â”‚  â”‚ - im2col_cuda â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ ç›®å½•ç»“æ„

```
kernels/
â”œâ”€â”€ README.md           # æœ¬æ–‡ä»¶
â”œâ”€â”€ CMakeLists.txt      # æ„å»ºé…ç½®
â””â”€â”€ cpu/                # CPUå®ç°
    â”œâ”€â”€ gemm_cpu.cpp    # GEMMå®ç°
    â””â”€â”€ im2col_cpu.cpp  # Im2Colå®ç°
```

### æœªæ¥è§„åˆ’
```
kernels/
â”œâ”€â”€ cuda/               # GPUå®ç°
â”‚   â”œâ”€â”€ gemm_cuda.cu
â”‚   â”œâ”€â”€ gemm_cublas.cu
â”‚   â””â”€â”€ im2col_cuda.cu
â”œâ”€â”€ cpu/
â”‚   â”œâ”€â”€ gemm_cpu.cpp          # åŸºç¡€å®ç°
â”‚   â”œâ”€â”€ gemm_cpu_avx2.cpp     # AVX2ä¼˜åŒ–
â”‚   â”œâ”€â”€ gemm_cpu_avx512.cpp   # AVX512ä¼˜åŒ–
â”‚   â””â”€â”€ gemm_blas.cpp         # BLASåŒ…è£…
â””â”€â”€ arm/                # ARM NEONä¼˜åŒ–
    â””â”€â”€ gemm_neon.cpp
```

## ğŸ”§ å·²å®ç°çš„Kernel

### 1. GEMM (General Matrix Multiplication)

**ä½ç½®**: `cpu/gemm_cpu.cpp`

**æ¥å£**:
```cpp
namespace kernels {
class GEMMKernel {
    // C = A @ B
    template<typename T>
    static void gemm_nn(const T* A, const T* B, T* C, 
                       int M, int N, int K);
    
    // C = A @ B^T  
    template<typename T>
    static void gemm_nt(const T* A, const T* B, T* C,
                       int M, int N, int K);
};
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```cpp
// Conv2Dä¸­ä½¿ç”¨
kernels::GEMMKernel::gemm_nn<float>(
    weight, col_buffer, output, 
    C_out, H_out*W_out, C_in*kH*kW
);

// Linearä¸­ä½¿ç”¨
kernels::GEMMKernel::gemm_nt<float>(
    input, weight, output,
    batch_size, out_features, in_features
);
```

**æ€§èƒ½ç‰¹ç‚¹**:
- âœ… å¾ªç¯å±•å¼€ï¼ˆ4å…ƒç´ /æ¬¡ï¼‰
- â³ æœªæ¥ï¼šAVX2/AVX512å‘é‡åŒ–
- â³ æœªæ¥ï¼šOpenMPå¹¶è¡ŒåŒ–
- â³ æœªæ¥ï¼šCache blockingä¼˜åŒ–

### 2. Im2Col (Image to Column)

**ä½ç½®**: `cpu/im2col_cpu.cpp`

**æ¥å£**:
```cpp
namespace kernels {
class Im2ColKernel {
    template<typename T>
    static void im2col(
        const T* input, T* col_buffer,
        int channels, int height, int width,
        int kernel_h, int kernel_w,
        int stride_h, int stride_w,
        int padding_h, int padding_w,
        int dilation_h, int dilation_w,
        int out_height, int out_width
    );
};
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```cpp
// Conv2Dä¸­ä½¿ç”¨
kernels::Im2ColKernel::im2col<float>(
    input_n, col_buffer.data(),
    C_in, H_in, W_in,
    kernel_h, kernel_w,
    stride_h, stride_w,
    padding_h, padding_w,
    dilation_h, dilation_w,
    H_out, W_out
);
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–è·¯å¾„

### CPUä¼˜åŒ–

1. **å½“å‰ï¼ˆv1.0ï¼‰**: æœ´ç´ å®ç°
   - å¾ªç¯å±•å¼€
   - ç¼“å­˜å‹å¥½çš„è®¿é—®æ¨¡å¼

2. **çŸ­æœŸï¼ˆv1.1ï¼‰**: SIMDå‘é‡åŒ–
   ```cpp
   // AVX2: 8ä¸ªfloat/æ¬¡
   __m256 a = _mm256_load_ps(&A[i]);
   __m256 b = _mm256_load_ps(&B[i]);
   __m256 c = _mm256_fmadd_ps(a, b, c);
   ```

3. **ä¸­æœŸï¼ˆv1.2ï¼‰**: BLASé›†æˆ
   ```cpp
   #ifdef USE_OPENBLAS
       cblas_sgemm(...);
   #else
       gemm_cpu(...);
   #endif
   ```

4. **é•¿æœŸï¼ˆv2.0ï¼‰**: è‡ªé€‚åº”ä¼˜åŒ–
   ```cpp
   // è¿è¡Œæ—¶é€‰æ‹©æœ€ä¼˜kernel
   if (M > 1024 && N > 1024)
       gemm_blas(...);      // å¤§çŸ©é˜µç”¨BLAS
   else
       gemm_cpu_avx2(...);  // å°çŸ©é˜µç”¨AVX2
   ```

### GPUä¼˜åŒ–

```cpp
// CUDAå®ç°ï¼ˆæœªæ¥ï¼‰
template<>
void GEMMKernel::gemm_nn<float>(
    const float* A, const float* B, float* C,
    int M, int N, int K,
    KernelBackend::CUDA) {
    
    // Option 1: cuBLAS
    cublasSgemm(handle, ...);
    
    // Option 2: è‡ªå®šä¹‰CUDA kernel
    gemm_kernel<<<grid, block>>>(A, B, C, M, N, K);
    
    // Option 3: CUTLASSæ¨¡æ¿åº“
    cutlass::gemm::device::Gemm<...> gemm_op;
    gemm_op(M, N, K, ...);
}
```

## ğŸ“Š Benchmarkç›®æ ‡

| æ“ä½œ | å½“å‰ | v1.1 (AVX2) | v1.2 (BLAS) | v2.0 (CUDA) |
|------|------|-------------|-------------|-------------|
| GEMM (1024x1024) | 100ms | 25ms | 10ms | 1ms |
| Conv2D (224x224x64) | 500ms | 125ms | 50ms | 5ms |

## ğŸ”Œ æ‰©å±•æŒ‡å—

### æ·»åŠ æ–°çš„CPUä¼˜åŒ–ç‰ˆæœ¬

1. åˆ›å»ºæ–‡ä»¶: `cpu/gemm_cpu_avx2.cpp`
2. å®ç°ä¼˜åŒ–ç‰ˆæœ¬:
```cpp
namespace kernels {
namespace cpu {
namespace avx2 {
    template<typename T>
    void gemm_nn_impl(...) {
        // AVX2å®ç°
    }
}
}
}
```

3. æ›´æ–°dispatcher:
```cpp
template<typename T>
void GEMMKernel::gemm_nn(..., KernelBackend backend) {
    switch (backend) {
        case KernelBackend::CPU_AVX2:
            cpu::avx2::gemm_nn_impl<T>(...);
            break;
        default:
            cpu::gemm_nn_impl<T>(...);
    }
}
```

### æ·»åŠ CUDAæ”¯æŒ

1. åˆ›å»ºæ–‡ä»¶: `cuda/gemm_cuda.cu`
2. CMakeLists.txt:
```cmake
if(USE_CUDA)
    enable_language(CUDA)
    target_sources(mini_infer_kernels PRIVATE
        cuda/gemm_cuda.cu
        cuda/im2col_cuda.cu
    )
    target_compile_options(mini_infer_kernels PRIVATE
        $<$<COMPILE_LANGUAGE:CUDA>:-arch=sm_75>
    )
endif()
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [How to Optimize GEMM](https://github.com/flame/how-to-optimize-gemm)
- [Caffe Im2Col](https://github.com/BVLC/caffe/blob/master/src/caffe/util/im2col.cpp)
- [cuBLAS Documentation](https://docs.nvidia.com/cuda/cublas/)
- [Intel MKL](https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html)
- [CUTLASS](https://github.com/NVIDIA/cutlass)

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®æ–°çš„kernelå®ç°ï¼è¯·ç¡®ä¿ï¼š

1. âœ… ä¿æŒæ¥å£ä¸€è‡´æ€§
2. âœ… æ·»åŠ å•å…ƒæµ‹è¯•
3. âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•
4. âœ… æ–‡æ¡£å’Œæ³¨é‡Š
5. âœ… è·¨å¹³å°å…¼å®¹æ€§
